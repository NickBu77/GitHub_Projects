{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size: 40px;'> Lending Club - ML Modeling with LightGBM </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style='font-size: 15px;'> Lending Club is an online peer-to-peer lending platform that allows small-dollar investors to lend borrower small unsecured personal loans. The interest rate charged on the loan is done on the basis of the grades and subgrades formulated by Lending Club. The method of calculating these grades is not transparent and the purpose of this project is to try to determine which variables are most strongly correlated with a loan being paid off by the end of its term, through a combination of statistical and visual analysis, as well as attempting to train a machine learning model to match the results or surpass those found in the datset.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tabulate import tabulate\n",
    "import textwrap\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,  classification_report\n",
    "import lightgbm as lgb\n",
    "# from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97258\\AppData\\Local\\Temp\\ipykernel_19756\\1839735408.py:1: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  initial_df = pd.read_csv(r'data\\csv_files\\accepted_2007_to_2018Q4.csv', encoding=\"ISO-8859-1\")\n"
     ]
    }
   ],
   "source": [
    "initial_df = pd.read_csv(r'LC_ML_Project\\csv_files\\accepted_2007_to_2018Q4.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size: 30px;'> Preliminary analysis and data cleaning </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2.3M rows and 151 columns. That's a lot of data to parse. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2260701, 151)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loan status is the dependent variable we want to understand. This dataset reflects the loan status of every loan as of 2018 Q4 and includes many loans in progress. We want to simplify the analysis and keep only the loans that reached the end of their term already. This is indicated by the Fully Paid or Charged Off designations. There are additional Fully Paid and Charged Off categories, preceeded by \"Does not meet the credit policy.\" Let's analyze whether to include these or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "Fully Paid                                             1076751\n",
       "Current                                                 878317\n",
       "Charged Off                                             268559\n",
       "Late (31-120 days)                                       21467\n",
       "In Grace Period                                           8436\n",
       "Late (16-30 days)                                         4349\n",
       "Does not meet the credit policy. Status:Fully Paid        1988\n",
       "Does not meet the credit policy. Status:Charged Off        761\n",
       "Default                                                     40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the below. I would like to include the Fully Paid and Charge Offs that do meet the current credit policy. The inclusion of them gives us more data to work with while not materially reducing the repayment rate, which stands at around 80%. We want to conduct statistical analysis independently without being biased by LC's credit policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking payback rate of the 'does not meets':\n",
      "loan_status\n",
      "Does not meet the credit policy. Status:Fully Paid     0.723172\n",
      "Does not meet the credit policy. Status:Charged Off    0.276828\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Checking payback rate of just the regular final statuses:\n",
      "loan_status\n",
      "Fully Paid     0.800374\n",
      "Charged Off    0.199626\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Checking payback rate all final statuses:\n",
      "loan_status\n",
      "Fully Paid                                             0.798742\n",
      "Charged Off                                            0.199219\n",
      "Does not meet the credit policy. Status:Fully Paid     0.001475\n",
      "Does not meet the credit policy. Status:Charged Off    0.000565\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking payback rate of the 'does not meets':\") \n",
    "print(initial_df.loc[initial_df['loan_status'].str.contains('Does not meet the credit policy'),'loan_status'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nChecking payback rate of just the regular final statuses:\") \n",
    "print(initial_df.loc[initial_df['loan_status'].isin(['Fully Paid','Charged Off']),'loan_status'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nChecking payback rate for all final statuses:\") \n",
    "print(initial_df.loc[initial_df['loan_status'].str.contains('Fully Paid|Charged Off'),'loan_status'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue cleaning the Loan Status column by making it a binary choice being Fully Paid or Charged Off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97258\\AppData\\Local\\Temp\\ipykernel_19756\\2278980541.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  modified_df['loan_status'] = modified_df['loan_status'].replace('Charged Off',0)\n",
      "C:\\Users\\97258\\AppData\\Local\\Temp\\ipykernel_19756\\2278980541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  modified_df['loan_status'] = modified_df['loan_status'].replace('Does not meet the credit policy. Status:Charged Off',0)\n"
     ]
    }
   ],
   "source": [
    "# Dropping any NAs in the loan status column\n",
    "modified_df = initial_df.dropna(subset=['loan_status'])\n",
    "\n",
    "# Replacing categorical column with numeric values, 1 for paid, 0 for charged off\n",
    "modified_df.loc[modified_df['loan_status'].str.contains('Fully Paid'), 'loan_status'] = 1\n",
    "modified_df['loan_status'] = modified_df['loan_status'].replace('Charged Off',0)\n",
    "\n",
    "# There are fully paid and charged off loans with slightly different \n",
    "modified_df['loan_status'] = modified_df['loan_status'].replace('Does not meet the credit policy. Status:Charged Off',0)\n",
    "\n",
    "# Lastly, because only the completed loans have been converted to boolian data types, I will now coerce all non-numeric values, meaning they will be dropped\n",
    "\n",
    "modified_df = modified_df[pd.to_numeric(modified_df['loan_status'], errors='coerce').notna()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We confirm below that the repayment rate after all of the data cleaning above remains at around 80%. It is. Based on the below counts, it look like 80% of the loans were fully repaid and 20% were charged-off. 80% is the mark we want to try to best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value count by final Loan Status: \n",
      "+--------------+-----------+\n",
      "| Final Status | Frequency |\n",
      "+--------------+-----------+\n",
      "|      1       |  1078739  |\n",
      "|      0       |  269320   |\n",
      "+--------------+-----------+\n",
      "\n",
      "Percentage by final Loan Status: \n",
      "+--------------+------------+\n",
      "| Final Status | Percentage |\n",
      "+--------------+------------+\n",
      "|      1       |   80.02    |\n",
      "|      0       |   19.98    |\n",
      "+--------------+------------+\n"
     ]
    }
   ],
   "source": [
    "# Creating table of counts\n",
    "value_cts = modified_df['loan_status'].value_counts().reset_index()\n",
    "value_cts.columns = ['Final Status', 'Frequency']\n",
    "\n",
    "# Creating table of percentages\n",
    "value_perc = modified_df['loan_status'].value_counts(normalize=True)*100\n",
    "value_perc = value_perc.reset_index()\n",
    "value_perc.columns = ['Final Status', 'Percentage']\n",
    "value_perc['Percentage'] = round(value_perc['Percentage'], 2)\n",
    "\n",
    "# Print table of value counts\n",
    "count_table = tabulate(value_cts.to_dict('records'), headers='keys', tablefmt='pretty')\n",
    "print(f'Value count by final Loan Status: \\n{count_table}\\n')\n",
    "\n",
    "# Print table of value percentages\n",
    "perc_table = tabulate(value_perc.to_dict('records'), headers='keys', tablefmt='pretty')\n",
    "print(f'Percentage by final Loan Status: \\n{perc_table}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next check for nulls and remove any columns above 50%. Because there are so many columns, many of them similar to others, we are comfortable with this strict dropoff rule at 50% even though may be columns right above the edge that could be of value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member_id                                     100.00\n",
      "next_pymnt_d                                   99.80\n",
      "orig_projected_additional_accrued_interest     99.72\n",
      "hardship_dpd                                   99.57\n",
      "hardship_type                                  99.57\n",
      "hardship_reason                                99.57\n",
      "hardship_status                                99.57\n",
      "deferral_term                                  99.57\n",
      "hardship_amount                                99.57\n",
      "hardship_start_date                            99.57\n",
      "payment_plan_start_date                        99.57\n",
      "hardship_length                                99.57\n",
      "hardship_end_date                              99.57\n",
      "hardship_loan_status                           99.57\n",
      "hardship_payoff_balance_amount                 99.57\n",
      "hardship_last_payment_amount                   99.57\n",
      "sec_app_mths_since_last_major_derog            99.51\n",
      "sec_app_revol_util                             98.64\n",
      "sec_app_chargeoff_within_12_mths               98.62\n",
      "sec_app_fico_range_high                        98.62\n",
      "sec_app_earliest_cr_line                       98.62\n",
      "sec_app_inq_last_6mths                         98.62\n",
      "sec_app_mort_acc                               98.62\n",
      "sec_app_open_acc                               98.62\n",
      "sec_app_open_act_il                            98.62\n",
      "sec_app_num_rev_accts                          98.62\n",
      "sec_app_fico_range_low                         98.62\n",
      "sec_app_collections_12_mths_ex_med             98.62\n",
      "revol_bal_joint                                98.62\n",
      "verification_status_joint                      98.10\n",
      "dti_joint                                      98.09\n",
      "annual_inc_joint                               98.09\n",
      "settlement_percentage                          97.53\n",
      "settlement_amount                              97.53\n",
      "settlement_date                                97.53\n",
      "settlement_status                              97.53\n",
      "debt_settlement_flag_date                      97.53\n",
      "settlement_term                                97.53\n",
      "desc                                           90.66\n",
      "mths_since_last_record                         82.98\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "perc_null = round(100*(modified_df.isnull().sum()/len(modified_df.id)), 2)\n",
    "print(perc_null.loc[perc_null > 0].sort_values(ascending=False)[0:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decreased our column count from 151 to 93."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows, columns: (1348059, 93)\n"
     ]
    }
   ],
   "source": [
    "fifty_null = perc_null[perc_null>50].index\n",
    "mod_df_2 = modified_df.drop(columns=fifty_null)\n",
    "print(f'# of rows, columns: {mod_df_2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the column names are unclear. After a search, I found a dictionary provided by LC explaining each column name. I pass this to a dataframed called 'definitions' and utilizing it create a dictionary for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An online resource from Lending Club that defines its terms\n",
    "\n",
    "definitions = pd.read_excel(\"https://resources.lendingclub.com/LCDataDictionary.xlsx\")\n",
    "\n",
    "columns_list = list(mod_df_2.columns)\n",
    "columns_dict = {}\n",
    "\n",
    "for col in columns_list:\n",
    "    value = list(definitions.loc[definitions['LoanStatNew'] == col,'Description'])\n",
    "    if value:\n",
    "        columns_dict[col] = value[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I looked up the definition of some returns to get an idea of the relevance of each column. A few examples are shown below, including initial_list_status. The F and W in the columns stand for whole or fractional and indicate whether investors were given the choice of funding a portion of the loan or had to lend the full requested amount. I'm less interested in the nuances of LC's platform and am more interested in more generalizable characteristics of borrowers. Therefore, I will drop this column in due course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The initial listing status of the loan. Possible values are – W, F'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_dict['initial_list_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created an additional dictionary to make it possible to search multiple entries that contain the same key word, in this case 'num_tl'. For two entries that contain this term in the key, the value tells us that they were \"updated in past 2 months.\" That indicates this information would have been unavailable at issuance and therefore are irrelevant for our analysis. I will drop these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_tl_120dpd_2m': 'Number of accounts currently 120 days past due (updated in past 2 months)',\n",
       " 'num_tl_30dpd': 'Number of accounts currently 30 days past due (updated in past 2 months)',\n",
       " 'num_tl_90g_dpd_24m': 'Number of accounts 90 or more days past due in last 24 months',\n",
       " 'num_tl_op_past_12m': 'Number of accounts opened in past 12 months'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tl_def = {key: value for key, value in columns_dict.items() if 'num_tl' in key}\n",
    "num_tl_def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I further searched to check if any other definitions include the word 'update' to get a hint as to which were updated after initial issuance, but I find that it's only the two original ones we stumbled on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num_tl_120dpd_2m', 'num_tl_30dpd']\n"
     ]
    }
   ],
   "source": [
    "updated_after = [key for key, value in columns_dict.items() if 'update' in value]\n",
    "print(updated_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a value count dictonary to make it easier to view the type of data in each column and the count of each unique value. I then run a function to see which columns have single values. These columns serve no use for our analysis since they have no predictive power, and are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_now_delinq\n",
      "0.0     1341688\n",
      "1.0        5979\n",
      "2.0         306\n",
      "3.0          42\n",
      "4.0          10\n",
      "5.0           3\n",
      "6.0           1\n",
      "14.0          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def v_count(category):\n",
    "    return mod_df_2[category].value_counts()\n",
    "\n",
    "print(v_count('acc_now_delinq'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pymnt_plan', 'out_prncp', 'out_prncp_inv', 'policy_code', 'hardship_flag']\n"
     ]
    }
   ],
   "source": [
    "single_values = []\n",
    "\n",
    "for col in mod_df_2.columns:\n",
    "    if len(v_count(col)) == 1:\n",
    "        single_values.append(col)\n",
    "\n",
    "print(single_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df_2 = mod_df_2.drop(columns=single_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After researching several fields through the methods explored above, I determined which columns can be dropped due to irrelevance to my analysis. Most would have been unavailable at issue. Others correspond closely to other columns, like fico_range_high, which is simply the fico_range_low column + 5. Others, like employment title is too subjective and varied to be of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unavailable_at_issue = ['tot_cur_bal','avg_cur_bal',  'total_pymnt', 'total_pymnt_inv',\n",
    "       'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries',\n",
    "       'collection_recovery_fee', 'last_pymnt_amnt', 'last_fico_range_high',\n",
    "       'last_fico_range_low','last_pymnt_d','last_credit_pull_d', 'num_tl_30dpd','num_tl_120dpd_2m', 'debt_settlement_flag']\n",
    "\n",
    "mod_df_2 = mod_df_2.drop(columns=unavailable_at_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97258\\AppData\\Local\\Temp\\ipykernel_19756\\512945082.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  mod_df_2['month'] = pd.to_datetime(mod_df_2['issue_d']).dt.month\n"
     ]
    }
   ],
   "source": [
    "# A month column may be useful. Let's create one before getting rid of the issue_date, which is too far in the past and likely reflects macroeconomic trends that won't be replicated as time progresses into the future\n",
    "mod_df_2['month'] = pd.to_datetime(mod_df_2['issue_d']).dt.month \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unhelpful_columns = ['url','title','zip_code','fico_range_high','funded_amnt_inv', 'emp_title', 'initial_list_status', 'id','issue_d']\n",
    "\n",
    "mod_df_2 = mod_df_2.drop(columns=unhelpful_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe has gone down from 151 to 63 now. We're getting there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns remaining: 63\n",
      "Index(['loan_amnt', 'funded_amnt', 'term', 'int_rate', 'installment', 'grade',\n",
      "       'sub_grade', 'emp_length', 'home_ownership', 'annual_inc',\n",
      "       'verification_status', 'loan_status', 'purpose', 'addr_state', 'dti',\n",
      "       'delinq_2yrs', 'earliest_cr_line', 'fico_range_low', 'inq_last_6mths',\n",
      "       'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc',\n",
      "       'collections_12_mths_ex_med', 'application_type', 'acc_now_delinq',\n",
      "       'tot_coll_amt', 'total_rev_hi_lim', 'acc_open_past_24mths',\n",
      "       'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'delinq_amnt',\n",
      "       'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op',\n",
      "       'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc',\n",
      "       'mths_since_recent_inq', 'num_accts_ever_120_pd', 'num_actv_bc_tl',\n",
      "       'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl',\n",
      "       'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats',\n",
      "       'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq',\n",
      "       'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens',\n",
      "       'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
      "       'total_il_high_credit_limit', 'disbursement_method', 'month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of columns remaining: {len(mod_df_2.columns)}')\n",
    "print(mod_df_2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final data cleaning manner: checking for any duplicates remaining. As it turns out, there are none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [loan_amnt, funded_amnt, term, int_rate, installment, grade, sub_grade, emp_length, home_ownership, annual_inc, verification_status, loan_status, purpose, addr_state, dti, delinq_2yrs, earliest_cr_line, fico_range_low, inq_last_6mths, open_acc, pub_rec, revol_bal, revol_util, total_acc, collections_12_mths_ex_med, application_type, acc_now_delinq, tot_coll_amt, total_rev_hi_lim, acc_open_past_24mths, bc_open_to_buy, bc_util, chargeoff_within_12_mths, delinq_amnt, mo_sin_old_il_acct, mo_sin_old_rev_tl_op, mo_sin_rcnt_rev_tl_op, mo_sin_rcnt_tl, mort_acc, mths_since_recent_bc, mths_since_recent_inq, num_accts_ever_120_pd, num_actv_bc_tl, num_actv_rev_tl, num_bc_sats, num_bc_tl, num_il_tl, num_op_rev_tl, num_rev_accts, num_rev_tl_bal_gt_0, num_sats, num_tl_90g_dpd_24m, num_tl_op_past_12m, pct_tl_nvr_dlq, percent_bc_gt_75, pub_rec_bankruptcies, tax_liens, tot_hi_cred_lim, total_bal_ex_mort, total_bc_limit, total_il_high_credit_limit, disbursement_method, month]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "print(mod_df_2[mod_df_2.duplicated()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
